{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese English Transliteration\n",
    "Ismail Abu Saiid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.nltk_contrib.fst.fst import *\n",
    "class myFST(FST):    \n",
    "    def recognize(self, iput, oput):\n",
    "        self.inp = list(iput)\n",
    "        self.outp = list(oput)     \n",
    "        if list(oput) == f.transduce(list(iput)):  \n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FST\n",
    "f = myFST('example')\n",
    "\n",
    "# Add states to the FST\n",
    "for i in range(92):\n",
    "    f.add_state(str(i))  # Adding states '0' through '91'\n",
    "\n",
    "f.initial_state = '0'  # Set initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a91'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define arcs for each syllable mapping\n",
    "\n",
    "# For 'āmóníyà': 'ammonia',\n",
    "f.add_arc('0', '1', ['ā'], ['am'])\n",
    "f.add_arc('1', '2', ['mó'], ['mo'])\n",
    "f.add_arc('2', '3', ['ní'], ['ni'])\n",
    "f.add_arc('3', '4', ['yà'], ['a'])\n",
    "\n",
    "# For 'āsīpílín': 'aspirin'\n",
    "f.add_arc('0', '5', ['ā'], ['as'])\n",
    "f.add_arc('5', '6', ['sī'], ['pi'])\n",
    "f.add_arc('6', '7', ['pí'], ['rin'])\n",
    "\n",
    "# For 'bèiguǒ': 'bagel'\n",
    "f.add_arc('0', '8', ['bèi'], ['ba'])\n",
    "f.add_arc('8', '9', ['guǒ'], ['gel'])\n",
    "\n",
    "# For 'bānzhuóqín': 'banjo'\n",
    "f.add_arc('0', '10', ['bān'], ['ban'])\n",
    "f.add_arc('10', '11', ['zhuó'], ['jo'])\n",
    "f.add_arc('11', '12', ['qín'], [''])\n",
    "\n",
    "# For 'bālěi': 'ballet'\n",
    "f.add_arc('0', '13', ['bā'], ['bal'])\n",
    "f.add_arc('13', '14', ['lěi'], ['let'])\n",
    "\n",
    "# For 'bùlǔsī': 'blues'\n",
    "f.add_arc('0', '15', ['bù'], ['blues'])\n",
    "\n",
    "# For 'bāshì': 'bus'\n",
    "f.add_arc('0', '16', ['bā'], ['bus'])\n",
    "f.add_arc('16', '17', ['shì'], [''])\n",
    "\n",
    "# For 'kāfēiyīn': 'caffeine'\n",
    "f.add_arc('0', '18', ['kā'], ['ca'])\n",
    "f.add_arc('18', '19', ['fēi'], ['fei'])\n",
    "f.add_arc('19', '20', ['yīn'], ['ine'])\n",
    "\n",
    "# For 'kǎlùlǐ': 'calorie'\n",
    "f.add_arc('0', '21', ['kǎ'], ['cal'])\n",
    "f.add_arc('21', '22', ['lù'], ['o'])\n",
    "f.add_arc('22', '23', ['lǐ'], ['rie'])\n",
    "\n",
    "# For 'kǎtōng': 'cartoon'\n",
    "f.add_arc('0', '24', ['kǎ'], ['car'])\n",
    "f.add_arc('24', '25', ['tōng'], ['toon'])\n",
    "\n",
    "# For 'zhīshì' : 'cheese'\n",
    "f.add_arc('0', '26', ['zhī'], ['chee'])\n",
    "f.add_arc('26', '27', ['shì'], ['se'])\n",
    "\n",
    "# For 'qiǎokèlì' : 'chocolate'\n",
    "f.add_arc('0', '28', ['qiǎo'], ['cho'])\n",
    "f.add_arc('28', '29', ['kè'], ['co'])\n",
    "f.add_arc('29', '30', ['lì'], ['late'])\n",
    "\n",
    "# For 'kāfēi' : 'coffee'\n",
    "f.add_arc('0', '31', ['kā'], ['cof'])\n",
    "f.add_arc('31', '32', ['fēi'], ['fee'])\n",
    "\n",
    "# For 'qǔqí' : 'cookie'\n",
    "f.add_arc('0', '33', ['qǔ'], ['coo'])\n",
    "f.add_arc('33', '34', ['qí'], ['kie'])\n",
    "\n",
    "# For 'shāfā' : 'sofa'\n",
    "f.add_arc('0', '35', ['shā'], ['so'])\n",
    "f.add_arc('35', '36', ['fā'], ['fa'])\n",
    "\n",
    "# For 'gālí' : 'curry'\n",
    "f.add_arc('0', '37', ['gā'], ['cur'])\n",
    "f.add_arc('37', '38', ['lí'], ['ry'])\n",
    "\n",
    "# For 'wéitāmìng' : 'vitamin'\n",
    "f.add_arc('0', '39', ['wéi'], ['vi'])\n",
    "f.add_arc('39', '40', ['tā'], ['ta'])\n",
    "f.add_arc('40', '41', ['mìng'], ['min'])\n",
    "\n",
    "# For 'tǔsī' : 'toast'\n",
    "f.add_arc('0', '42', ['tǔ'], ['toast'])\n",
    "f.add_arc('42', '43', ['sī'], [''])\n",
    "\n",
    "# For 'délǜfēng' : 'telephone'\n",
    "f.add_arc('0', '44', ['dé'], ['te'])\n",
    "f.add_arc('44', '45', ['lǜ'], ['le'])\n",
    "f.add_arc('45', '46', ['fēng'], ['phone'])\n",
    "\n",
    "# For 'shìduōpílí' : 'strawberry'\n",
    "f.add_arc('0', '47', ['shì'], ['straw'])\n",
    "f.add_arc('47', '48', ['duō'], ['ber'])\n",
    "f.add_arc('48', '49', ['pí'], ['ry'])\n",
    "f.add_arc('49', '50', ['lí'], [''])\n",
    "\n",
    "# For 'sāngná' : 'health'\n",
    "f.add_arc('0', '51', ['sān'], ['health'])\n",
    "f.add_arc('51', '52', ['ná'], [''])\n",
    "\n",
    "# For 'mǎkèbēi' : 'mug'\n",
    "f.add_arc('0', '53', ['mǎ'], ['mug'])\n",
    "f.add_arc('53', '54', ['kè'], [''])\n",
    "f.add_arc('54', '55', ['bēi'], [''])\n",
    "\n",
    "# For 'màikèfēng' : 'microphone'\n",
    "f.add_arc('0', '56', ['mài'], ['mi'])\n",
    "f.add_arc('56', '57', ['kè'], ['cro'])\n",
    "f.add_arc('57', '58', ['fēng'], ['phone'])\n",
    "\n",
    "# For 'mǎshājī' : 'massage'\n",
    "f.add_arc('0', '59', ['mǎ'], ['mas'])\n",
    "f.add_arc('59', '60', ['shā'], ['sage'])\n",
    "f.add_arc('60', '61', ['jī'], [''])\n",
    "\n",
    "# For 'níngméng' : 'lemon'\n",
    "f.add_arc('0', '62', ['níng'], ['le'])\n",
    "f.add_arc('62', '63', ['méng'], ['mon'])\n",
    "\n",
    "# For 'jiākè' : 'jacket'\n",
    "f.add_arc('0', '64', ['jiā'], ['jack'])\n",
    "f.add_arc('64', '65', ['kè'], ['et'])\n",
    "\n",
    "# For 'sùkèdá' : 'scooter'\n",
    "f.add_arc('0', '66', ['sù'], ['scoo'])\n",
    "f.add_arc('66', '67', ['kè'], ['ter'])\n",
    "f.add_arc('67', '68', ['dá'], [''])\n",
    "\n",
    "# For 'xiāngbō' : 'shampoo'\n",
    "f.add_arc('0', '69', ['xiāng'], ['sham'])\n",
    "f.add_arc('69', '70', ['bō'], ['poo'])\n",
    "\n",
    "# For 'shìduōpílí' : 'strawberry'\n",
    "f.add_arc('0', '71', ['shì'], ['straw'])\n",
    "f.add_arc('71', '72', ['duō'], ['ber'])\n",
    "f.add_arc('72', '73', ['pí'], ['ry'])\n",
    "f.add_arc('73', '74', ['lí'], [''])\n",
    "\n",
    "# For 'jítā' : 'guitar'\n",
    "f.add_arc('0', '75', ['jí'], ['gui'])\n",
    "f.add_arc('75', '76', ['tā'], ['tar'])\n",
    "\n",
    "# For 'hāní' : 'honey'\n",
    "f.add_arc('0', '77', ['hā'], ['ho'])\n",
    "f.add_arc('77', '78', ['ní'], ['ney'])\n",
    "\n",
    "# For 'léishè' : 'laser'\n",
    "f.add_arc('0', '79', ['léi'], ['la'])\n",
    "f.add_arc('79', '80', ['shè'], ['ser'])\n",
    "\n",
    "# For 'nílóng' : 'nylon'\n",
    "f.add_arc('0', '81', ['ní'], ['ny'])\n",
    "f.add_arc('81', '82', ['lóng'], ['lon'])\n",
    "\n",
    "# For 'dīshì' : 'taxi'\n",
    "f.add_arc('0', '83', ['dī'], ['taxi'])\n",
    "f.add_arc('83', '84', ['shì'], [''])\n",
    "\n",
    "# For 'yújiā': 'yoga'\n",
    "f.add_arc('0', '85', ['yú'], ['yo'])\n",
    "f.add_arc('85', '86', ['jiā'], ['ga'])\n",
    "\n",
    "# For 'bēngdài': 'bandage'\n",
    "f.add_arc('0', '87', ['bēng'], ['ban'])\n",
    "f.add_arc('87', '88', ['dài'], ['dage'])\n",
    "\n",
    "# For 'sāngná': 'health'\n",
    "f.add_arc('0', '89', ['sān'], ['health'])\n",
    "f.add_arc('89', '90', ['g'], [''])\n",
    "f.add_arc('90', '91', ['ná'], [''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syllables with multiple translations (not including final states for these syllables unless they are the last syllable of the word)\n",
    "# 'ā': ['am', 'as']             State: 1,5\n",
    "# 'ní': ['ni', 'ney', 'ny']     State: 3, 81\n",
    "# 'sī': ['pi', '']              State: 6\n",
    "# 'pí': ['rin', 'ry']           State: 49, 73\n",
    "# 'bā': ['bal', 'bus']          State: 13, 16\n",
    "# 'shì': ['','se','straw',]     State: 47, 71\n",
    "# 'lí': ['ry', '']              State: \n",
    "# 'tā': ['ta','tar']            State: 40\n",
    "# 'jiā': ['jack','ga']          State: 64\n",
    "\n",
    "numbers_to_skip = {1, 5, 3, 81, 6, 49, 73, 13, 16, 47, 71, 40, 64}\n",
    "\n",
    "# Add final states to the FST\n",
    "for num in range(1, 92):\n",
    "    if num not in numbers_to_skip:\n",
    "        f.set_final(str(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hā ní\n",
      "ho ney\n",
      "accept\n"
     ]
    }
   ],
   "source": [
    "# Testing the FST\n",
    "# If input is only a single syllable that has multiple translations it will be rejected\n",
    "\n",
    "inp = 'hā ní'\n",
    "outp = 'ho ney'\n",
    "print(inp)\n",
    "\n",
    "if f.recognize(inp.split(), outp.split()):\n",
    "    print(outp)\n",
    "    print(\"accept\")\n",
    "else:    \n",
    "    print(\"reject\")\n",
    "\n",
    "disp = FSTDisplay(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with the input-output mappings\n",
    "mappings = {\n",
    "    # For 'āmóníyà': 'ammonia',\n",
    "    'ā': ['am', 'as'],\n",
    "    'mó': 'mo',\n",
    "    'ní': ['ni', 'ney', 'ny'],\n",
    "    'yà': 'a',\n",
    "    'ā mó ní yà': 'am mo ni a',\n",
    "\n",
    "    # For 'āsīpílín': 'aspirin'\n",
    "    'ā': ['am', 'as'],\n",
    "    'sī': ['pi', ''],\n",
    "    'pí': ['rin', 'ry'],\n",
    "    'ā sī pí': 'as pi rin',\n",
    "\n",
    "    # For 'bèiguǒ': 'bagel'\n",
    "    'bèi': 'ba',\n",
    "    'guǒ': 'gel',\n",
    "    'bèi guǒ': 'ba gel',\n",
    "\n",
    "    # For 'bānzhuóqín': 'banjo'\n",
    "    'bān': 'ban',\n",
    "    'zhuó': 'jo',\n",
    "    'qín': '',\n",
    "    'bān zhuó qín': 'ban jo',\n",
    "\n",
    "    # For 'bālěi': 'ballet'\n",
    "    'bā': ['bal', 'bus'],\n",
    "    'lěi': 'let',\n",
    "    'bā lěi': 'bal let',\n",
    "\n",
    "    # For 'bùlǔsī': 'blues'\n",
    "    'bùlǔsī': 'blues',\n",
    "    'bù' : 'blues',\n",
    "\n",
    "    # For 'bāshì': 'bus'\n",
    "    'bā': ['bal', 'bus'],\n",
    "    'shì': ['','se','straw',],\n",
    "    'bā shì': 'bus',\n",
    "\n",
    "    # For 'kāfēiyīn': 'caffeine'\n",
    "    'kā' : 'ca',\n",
    "    'fēi' : 'fei',\n",
    "    'yīn' : 'ine',\n",
    "    'kāfēiyīn' : 'caffeine',\n",
    "\n",
    "    # For 'kǎlùlǐ': 'calorie'\n",
    "    'kǎ': 'cal',\n",
    "    'lù': 'o',\n",
    "    'lǐ': 'rie',\n",
    "    'kǎ lù lǐ': 'cal o rie',\n",
    "\n",
    "    # For 'kǎtōng': 'cartoon'\n",
    "    'kǎ': 'car',\n",
    "    'tōng': 'toon',\n",
    "    'kǎ tōng': 'car toon',\n",
    "\n",
    "    # For 'zhīshì' : 'cheese'\n",
    "    'zhī': 'chee',\n",
    "    'shì': ['','se','straw',],\n",
    "    'zhī shì': 'chee se',\n",
    "\n",
    "    # For 'qiǎokèlì' : 'chocolate'\n",
    "    'qiǎo': 'cho',\n",
    "    'kè': 'co',\n",
    "    'lì': 'late',\n",
    "    'qiǎo kè lì': 'cho co late',\n",
    "\n",
    "    # For 'kāfēi' : 'coffee'\n",
    "    'kā': 'cof',\n",
    "    'fēi': 'fee',\n",
    "    'kā fēi': 'cof fee',\n",
    "\n",
    "    # For 'qǔqí' : 'cookie'\n",
    "    'qǔ': 'coo',\n",
    "    'qí': 'kie',\n",
    "    'qǔ qí': 'coo kie',\n",
    "\n",
    "    # For 'shāfā' : 'sofa'\n",
    "    'shā': 'so',\n",
    "    'fā': 'fa',\n",
    "    'shā fā': 'so fa',\n",
    "\n",
    "    # For 'gālí' : 'curry'\n",
    "    'gā': 'cur',\n",
    "    'lí': ['ry', ''],\n",
    "    'gā lí': 'cur ry',\n",
    "\n",
    "    # For 'wéitāmìng' : 'vitamin'\n",
    "    'wéi': 'vi',\n",
    "    'tā': ['ta','tar'],\n",
    "    'mìng': 'min',\n",
    "    'wéi tā mìng': 'vi ta min',\n",
    "\n",
    "    # For 'tǔsī' : 'toast'\n",
    "    'tǔ': 'toast',\n",
    "    'sī': ['pi', ''],\n",
    "    'tǔ sī': 'toast ',\n",
    "\n",
    "    # For 'délǜfēng' : 'telephone\n",
    "    'dé': 'te',\n",
    "    'lǜ': 'le',\n",
    "    'fēng': 'phone',\n",
    "    'dé lǜ fēng': 'te le phone',\n",
    "\n",
    "    # For 'shìduōpílí' : 'strawberry'\n",
    "    'shì': ['','se','straw',],\n",
    "    'duō': 'ber',\n",
    "    'pí': 'ry',\n",
    "    'lí': '',\n",
    "    'shì duō pí lí': 'straw ber ry',\n",
    "\n",
    "    # For 'sāngná' : 'health'\n",
    "    'sān': 'health',\n",
    "    'ná': '',\n",
    "    'sānná': 'health',\n",
    "\n",
    "    # For 'mǎkèbēi' : 'mug'\n",
    "    'mǎ': 'mug',\n",
    "    'kè': '',\n",
    "    'bēi': '',\n",
    "    'mǎ kè bēi': 'mug',\n",
    "\n",
    "    # For 'màikèfēng' : 'microphone'\n",
    "    'mài': 'mi',\n",
    "    'kè': 'cro',\n",
    "    'fēng': 'phone',\n",
    "    'mài kè fēng': 'mi cro phone',\n",
    "\n",
    "    # For 'mǎshājī' : 'massage'\n",
    "    'mǎ': 'mas',\n",
    "    'shā': 'sage',\n",
    "    'jī': '',\n",
    "    'mǎ shā jī': 'mas sage',\n",
    "\n",
    "    # For 'níngméng' : 'lemon'\n",
    "    'níng': 'le',\n",
    "    'méng': 'mon',\n",
    "    'níng méng': 'le mon',\n",
    "\n",
    "    # For 'jiākè' : 'jacket'\n",
    "    'jiā': ['jack','ga'],\n",
    "    'kè': 'et',\n",
    "    'jiā kè': 'jack et',\n",
    "\n",
    "    # For 'sùkèdá' : 'scooter'\n",
    "    'sù': 'scoo',\n",
    "    'kè': 'ter',\n",
    "    'dá': '',\n",
    "    'sù kè dá': 'scoo ter',\n",
    "\n",
    "    # For 'xiāngbō' : 'shampoo'\n",
    "    'xiāng': 'sham',\n",
    "    'bō': 'poo',\n",
    "    'xiāng bō': 'sham poo',\n",
    "\n",
    "    # For 'shìduōpílí' : 'strawberry'\n",
    "    'shì': ['','se','straw',],\n",
    "    'duō': 'ber',\n",
    "    'pí': ['rin' 'ry'],\n",
    "    'lí': ['ry', ''],\n",
    "    'shì duō pí lí': 'straw ber ry',\n",
    "\n",
    "    # For 'jítā' : 'guitar'\n",
    "    'jí': 'gui',\n",
    "    'tā': ['ta','tar'],\n",
    "    'jí tā': 'gui tar',\n",
    "\n",
    "    # For 'hāní' : 'honey'\n",
    "    'hā': 'ho',\n",
    "    'ní': ['ni', 'ney', 'ny'],\n",
    "    'hāní': 'ho ney',\n",
    "\n",
    "    # For 'léishè' : 'laser'\n",
    "    'léi': 'la',\n",
    "    'shè': 'ser',\n",
    "    'léi shè': 'la ser',\n",
    "\n",
    "    # For 'nílóng' : 'nylon'\n",
    "    'ní': ['ni', 'ney', 'ny'],\n",
    "    'lóng': 'lon',\n",
    "    'ní lóng': 'ny lon',\n",
    "\n",
    "    # For 'dīshì' : 'taxi'\n",
    "    'dī': 'taxi',\n",
    "    'shì': ['','se','straw',],\n",
    "    'dī shì': 'taxi ',\n",
    "\n",
    "    # For 'yújiā': 'yoga'\n",
    "    'yú': 'yo',\n",
    "    'jiā': ['jack','ga'],\n",
    "    'yú jiā': 'yo ga',\n",
    "    \n",
    "    # For 'bēngdài': 'bandage'\n",
    "    'bēng' : 'ban',\n",
    "    'dài' : 'dage',\n",
    "    'bēngdài' : 'bandage'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all input-output mappings into an output file named Chinglish-trans.dat\n",
    "with open('Chinglish-trans.dat', 'w', encoding='utf-8') as file:\n",
    "    for syllable, word in mappings.items():\n",
    "        file.write(f\"{syllable} --> {word}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all possible input-output result into input-output-results\n",
    "with open('input-output-results.dat', 'w', encoding='utf-8') as file:\n",
    "    # Redirecting the prints to the file\n",
    "    for input_syllable, expected_output in mappings.items():\n",
    "        output_string = ''\n",
    "        if isinstance(expected_output, list):\n",
    "            # If the expected output is a list, iterate through its elements\n",
    "            for output in expected_output:\n",
    "                if f.recognize(input_syllable.split(), output.split()):\n",
    "                    output_string += f\"Input: {input_syllable}, Output: {output}, Accepted\\n\"\n",
    "                else:\n",
    "                    output_string += f\"Input: {input_syllable}, Output: {output}, Rejected\\n\"\n",
    "        else:\n",
    "            if f.recognize(input_syllable.split(), expected_output.split()):\n",
    "                output_string += f\"Input: {input_syllable}, Output: {expected_output}, Accepted\\n\"\n",
    "            else:\n",
    "                output_string += f\"Input: {input_syllable}, Output: {expected_output}, Rejected\\n\"\n",
    "        file.write(output_string)  # Writes to file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
